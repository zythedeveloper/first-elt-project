# Custom ELT Project

This project is based on Justin B. Chau's tutorial on FreeCodeCamp's YouTube channel. It explores the creation and deployment of a custom Extract, Load, and Transform (ELT) pipeline, demonstrating practical data engineering concepts and techniques.

## Overview

The **Custom ELT Project** integrates a variety of modern technologies to streamline data workflows, providing a comprehensive learning experience in building scalable and maintainable data systems.

## Key Technologies

1. **Docker**
   - Utilized for containerizing applications, ensuring consistency across development and production environments.
   - Simplifies dependency management and deployment for the project components.

2. **Postgres Database**
   - Serves as the relational database management system for data storage and querying.
   - Demonstrates efficient handling of structured datasets.

3. **dbt (Data Build Tool)**
   - Empowers users to perform data transformations in a modular and version-controlled manner.
   - Simplifies the creation and management of complex data models.

4. **Apache Airflow**
   - Facilitates the orchestration of ELT workflows, automating the scheduling and execution of data pipelines.
   - Uses Directed Acyclic Graphs (DAGs) to define and monitor tasks within the pipeline.

## Project Highlights

The project guides users through the process of setting up a robust ELT pipeline, covering:

- Extracting raw data from various sources.
- Loading data into a Postgres database.
- Transforming raw data into actionable insights using dbt.
- Orchestrating workflows with Apache Airflow.

By completing this project, users gain valuable experience in:

- Containerization with Docker.
- Working with relational databases.
- Implementing transformations with dbt.
- Automating workflows using Airflow.

---

This repository serves as a practical resource for anyone looking to deepen their understanding of data engineering and the tools required to build modern ELT pipelines.
